{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e864d375",
   "metadata": {},
   "source": [
    "# What are Agents? -or-\n",
    "# LangChain Agents\n",
    "\n",
    "\n",
    "In Langchain, an Agent is a decision-making component that uses LLM to decide what action to take next -- based on user input, context and available tools\n",
    "\n",
    "Reasoning LLM  ---- LLM will decide from where to derive the solution\n",
    "\n",
    "The goal of these kind of applications is to achieve AUTONOMY !!!\n",
    "Let System Do THE DECISION-MAKING favorable for the business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa7708",
   "metadata": {},
   "source": [
    "# Key Jargon for Agents\n",
    "\n",
    "1. LLM as a Reasoner: This LLM doesnt just answer. ---- IT PLANS. It decides which step or tool to use next.\n",
    "\n",
    "2. Tools: External functions or API or MCP Servers that the agent can use (e.g. calculator, search, database query etc. )\n",
    "\n",
    "3. Prompting Loop (ReAct): The agent uses the LLM repeatedly to REASON,\n",
    "\n",
    "                    THINK -> ACT -> OBSERVE -> THINK -> ACT\n",
    "\n",
    "4. Intermediate Steps: Logs of all tool invocations and their outputs used to refine the reasoning.\n",
    "\n",
    "5. Output Parsers: Defines how the LLMs text output is converted into STRUCTURED ACTIONS or RESPONSES."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b45af",
   "metadata": {},
   "source": [
    "# Agent's Thought Process | Agent's Thought Cycle\n",
    "\n",
    "\n",
    "A typical agent operation may look like below:\n",
    "\n",
    "1. Receive user query (What is the current temperature in Pune and how is it as compared to yesterday?)\n",
    "\n",
    "2. Reasoning Step (LLM decide what to do:)\n",
    " -> I need to use a Weather API tool to get today's weather and get yesterday's weather\n",
    "\n",
    "3. Action Step\n",
    " -> Agent calls get_weather(city=\"Pune\")\n",
    "\n",
    "4. Observation\n",
    " -> The tool returned data -> Agent update its context\n",
    "\n",
    "5. Next Reasoning Step:\n",
    " -> LLM decides to compare both day's data.\n",
    "\n",
    "6. Final Answer:\n",
    " -> Agent generates a Natural Language Reply to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca7877c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e026bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents.openai_functions_agent.base import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d92bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define a tool\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Return a fake weather forecast for the given location.\"\"\"\n",
    "    # In a real build, you’d call a weather API here\n",
    "    return f\"The weather in {location} is sunny and 25 °C.\"\n",
    "\n",
    "tools = [get_weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5066fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Set up the LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a41803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Build the agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can call a weather tool.\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),  #Agent Scratchpad maintains all intermediate outputs\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "#Initializing the agent\n",
    "agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "#Making the agent executable | query-able\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0a660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_weather` with `{'location': 'Pune'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe weather in Pune is sunny and 25 °C.\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in Pune is sunny with a temperature of 25 °C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What’s the weather in Pune?', 'output': 'The weather in Pune is sunny with a temperature of 25 °C.'}\n"
     ]
    }
   ],
   "source": [
    "# 4) Invoke the agent\n",
    "result = agent_executor.invoke({\"input\": \"What’s the weather in Pune?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12674f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m2 + 2 equals 4.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What’s 2+2?', 'output': '2 + 2 equals 4.'}\n"
     ]
    }
   ],
   "source": [
    "# 4) Invoke the agent\n",
    "result = agent_executor.invoke({\"input\": \"What’s 2+2?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb65a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_weather` with `{'location': 'Pune'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe weather in Pune is sunny and 25 °C.\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in Pune is sunny and 25 °C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the weather in Pune?',\n",
       " 'output': 'The weather in Pune is sunny and 25 °C.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llmGemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\"\n",
    ")\n",
    "\n",
    "agent2 = create_tool_calling_agent(\n",
    "    llm=llmGemini,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ") \n",
    "\n",
    "executorGeminiAgent = AgentExecutor(agent=agent2, tools=tools, verbose=True)\n",
    "\n",
    "executorGeminiAgent.invoke({\"input\": \"Whats the weather in Pune?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87df5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
